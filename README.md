# PF Talent Search

A modern talent search application for finding and matching employees based on skills, experience, and job requirements. Built with React and FastAPI, featuring AI-powered persona generation and intelligent candidate matching.

## Features

- ðŸ” **Employee Search**: Search employees by name, email, ID, job title, or department
- ðŸ¤– **AI-Powered Persona Generation**: Generate detailed employee personas using configurable LLM providers (Azure OpenAI or Google Gemini)
- ðŸŽ¯ **Smart Matching**: Find similar employees and evaluate candidates based on criteria
- ðŸŒ **Multi-language Support**: English and Japanese interface
- ðŸŽ¨ **Modern UI**: Clean, responsive design with smooth animations
- ðŸ³ **Docker Support**: Easy deployment with Docker Compose

## Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **Configurable LLM** - Azure OpenAI or Google Gemini for AI-powered features
- **Python 3.11+**

### Frontend
- **React 18** - UI library
- **Vite** - Build tool and dev server
- **Framer Motion** - Animations
- **i18next** - Internationalization
- **Nginx** - Production web server

## Project Structure

```
pf-talentsearch/
â”œâ”€â”€ backend/                    # FastAPI backend
â”‚   â”œâ”€â”€ main.py                 # Main application
â”‚   â”œâ”€â”€ llm_service.py          # LLM abstraction layer (Azure OpenAI/Gemini)
â”‚   â”œâ”€â”€ data_validator.py       # Data validation for BigQuery schema
â”‚   â”œâ”€â”€ review_service.py       # Employee review data service
â”‚   â”œâ”€â”€ face_image_service.py   # Employee photo service (GCS or mock)
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ env.example             # Environment variables template
â”‚   â”œâ”€â”€ Dockerfile              # Backend container
â”‚   â”œâ”€â”€ scripts/                # Utility scripts
â”‚   â”‚   â””â”€â”€ convert_to_bigquery_schema.py
â”‚   â””â”€â”€ mock-data/              # Mock data directory
â”‚       â”œâ”€â”€ employees/          # Employee data (replace with BigQuery export)
â”‚       â”‚   â”œâ”€â”€ employees.json  # Main employee data file
â”‚       â”‚   â””â”€â”€ README.md       # Data import instructions
â”‚       â”œâ”€â”€ big_query_mock/     # BigQuery schema reference
â”‚       â”‚   â”œâ”€â”€ README.md       # Schema documentation and import guide
â”‚       â”‚   â”œâ”€â”€ schema_*.txt    # Schema documentation (JP/EN)
â”‚       â”‚   â””â”€â”€ sample_data_*.json
â”‚       â”œâ”€â”€ personas/           # Generated persona data
â”‚       â”œâ”€â”€ reviews/            # Employee review data (JSONL format)
â”‚       â”œâ”€â”€ resumes/            # Employee resume text files
â”‚       â””â”€â”€ photos/             # Employee photos (mock mode)
â”œâ”€â”€ frontend/                   # React frontend
â”‚   â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ public/                 # Static assets
â”‚   â”œâ”€â”€ Dockerfile              # Frontend container
â”‚   â””â”€â”€ package.json            # Node dependencies
â”œâ”€â”€ docker-compose.yml          # Local development setup
â””â”€â”€ README.md                   # This file
```

## Data Sources

### Employee Data (`backend/mock-data/employees/employees.json`)

**Source**: BigQuery table `prod_mart.mart_emp_search_employee_profile`

**How to Replace with Production Data**:

1. **Export from BigQuery**:
   ```sql
   SELECT *
   FROM `prod_mart.mart_emp_search_employee_profile`
   ORDER BY employee_id
   ```

2. **Export as JSON** (in BigQuery console or CLI):
   ```bash
   bq query --format=json --use_legacy_sql=false \
     "SELECT * FROM \`prod_mart.mart_emp_search_employee_profile\` ORDER BY employee_id" \
     > employees.json
   ```

3. **Copy to application**:
   ```bash
   cp employees.json backend/mock-data/employees/employees.json
   ```

4. **Verify**: The application will automatically validate the data on startup.

**Schema**: See `backend/mock-data/big_query_mock/README.md` for complete schema documentation.

**Note**: The application automatically converts BigQuery's hierarchical `dept_name` format to legacy `dept_1`, `dept_2`, etc. for backward compatibility.

### Other Data Sources

- **Personas** (`backend/mock-data/personas/`): Generated by LLM, stored for caching
- **Reviews** (`backend/mock-data/reviews/`): Employee review data in JSONL format
- **Resumes** (`backend/mock-data/resumes/`): Text files named `EMP{employee_id}_*.txt`
- **Photos** (`backend/mock-data/photos/`): Employee photos (mock mode) or GCS bucket (production)

## Configuration

### Environment Variables

All configuration is done through environment variables. Copy `backend/env.example` to `backend/.env` and fill in the values.

#### Required Variables

**LLM Provider Selection**:
- `LLM_PROVIDER` - Choose LLM provider: `azure_openai` or `google_gemini` (default: `azure_openai`)

**For Azure OpenAI** (when `LLM_PROVIDER=azure_openai`):
- `AZURE_OPENAI_ENDPOINT` - Your Azure OpenAI endpoint URL (e.g., `https://your-resource.openai.azure.com/`)
- `AZURE_OPENAI_API_KEY` - Your Azure OpenAI API key
- `AZURE_OPENAI_API_VERSION` - API version (default: `2024-10-21`)
- `AZURE_OPENAI_DEPLOYMENT` - Deployment name (default: `gpt-4o`)

**For Google Gemini** (when `LLM_PROVIDER=google_gemini`):
- `GOOGLE_GEMINI_API_KEY` - Your Google Gemini API key (get from https://makersuite.google.com/app/apikey)
- `GOOGLE_GEMINI_MODEL` - Model name (default: `gemini-1.5-pro`)

#### Optional Variables

**Face Image Service** (for production photo storage):
- `USE_MOCK_DATA` - Use mock photos instead of GCS (default: `true`)
- `GCS_BUCKET_NAME` - Google Cloud Storage bucket name (default: `pf_ai_app`)
- `GCS_PHOTOS_PATH` - Path prefix in GCS bucket (default: `photos`)
- `GOOGLE_APPLICATION_CREDENTIALS` - Path to GCS service account JSON file

### Quick Setup

1. **Copy environment template**:
   ```bash
   cd backend
   cp env.example .env
   ```

2. **Edit `.env` file** and set your LLM provider and API keys:
   ```env
   LLM_PROVIDER=azure_openai
   AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
   AZURE_OPENAI_API_KEY=your-api-key-here
   ```

3. **Replace employee data** (see Data Sources section above)

## Quick Start

### Prerequisites

- **Python 3.11+** (for backend)
- **Node.js 18+** (for frontend)
- **Docker** (optional, for containerized deployment)

### Option 1: Local Development

#### Backend Setup

1. Navigate to backend directory:
   ```bash
   cd backend
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Configure environment variables (see Configuration section above)

4. Run the server:
   ```bash
   uvicorn main:app --reload --port 8080
   ```

The backend will be available at `http://localhost:8080`
- API Docs: `http://localhost:8080/docs`

#### Frontend Setup

1. Navigate to frontend directory:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Run the development server:
   ```bash
   npm run dev
   ```

The frontend will be available at `http://localhost:5173`

### Option 2: Docker Compose (Recommended)

1. **Configure environment**:
   ```bash
   cd backend
   cp env.example .env
   # Edit .env with your API keys
   ```

2. **Build and start services**:
   ```bash
   docker-compose up --build
   ```

3. **Access the application**:
   - Frontend: `http://localhost:80`
   - Backend API: `http://localhost:8000`
   - API Docs: `http://localhost:8000/docs`

4. **Stop services**:
   ```bash
   docker-compose down
   ```

## API Endpoints

### Health & Testing
- `GET /api/health` - Health check endpoint
- `GET /api/test-llm` - Test LLM connection (shows configured provider)

### Employee Search
- `GET /api/people/{query}` - Search employees by name, email, ID, job title, or department
- `POST /api/search/natural-language` - Natural language search with LLM-powered query parsing
- `POST /api/search/similar-employees` - Find similar employees to a target
- `POST /api/search/filter` - Filter candidates by hard criteria
- `POST /api/search/evaluate` - Evaluate candidates with scoring
- `POST /api/search/evaluate/stream` - Stream evaluation results (SSE)

### Persona Generation
- `POST /api/persona` - Generate employee persona from data (requires LLM)

## Development

### Backend Development

The backend uses FastAPI with automatic API documentation:
- Swagger UI: `http://localhost:8080/docs`
- ReDoc: `http://localhost:8080/redoc`

### Frontend Development

The frontend uses Vite for fast hot module replacement:
- Development server: `http://localhost:5173`
- Build for production: `npm run build`

## Building for Production

### Backend

```bash
cd backend
docker build -t pf-talentsearch-backend:latest -f Dockerfile ..
```

### Frontend

```bash
cd frontend
docker build -t pf-talentsearch-frontend:latest -f Dockerfile .
```

## Deployment

### Docker Compose

For local or server deployment:
```bash
docker-compose up -d
```

### Individual Containers

```bash
# Backend
docker run -p 8000:8000 \
  -e LLM_PROVIDER=azure_openai \
  -e AZURE_OPENAI_ENDPOINT=... \
  -e AZURE_OPENAI_API_KEY=... \
  pf-talentsearch-backend:latest

# Frontend
docker run -p 80:80 pf-talentsearch-frontend:latest
```

## Troubleshooting

### Backend not starting
- Check if port 8080 (or 8000) is available
- Verify Python version (3.11+)
- Ensure all dependencies are installed
- Check `.env` file exists and has required variables

### LLM errors
- Verify `LLM_PROVIDER` is set correctly (`azure_openai` or `google_gemini`)
- Check API keys are correct in `.env` file
- For Azure OpenAI: Verify endpoint URL format and deployment name
- For Gemini: Verify API key from https://makersuite.google.com/app/apikey
- Test connection: `GET /api/test-llm`

### Frontend not connecting to backend
- Verify backend is running on `http://localhost:8080` (or configured port)
- Check CORS settings in backend
- For Docker, ensure services are on the same network

### Data validation errors
- Check `backend/mock-data/employees/employees.json` is valid JSON
- Verify data follows BigQuery schema (see `backend/mock-data/big_query_mock/README.md`)
- Check application logs for specific validation errors

## License

This project is proprietary software.

## Support

For issues and questions, please open an issue in the repository.
